# Исследование влияния аугментаций на эффективность сверточной нейронной сети

Этот проект представляет собой исследование влияния различных стратегий аугментации данных на качество классификации изображений с использованием сверточной нейронной сети. Эксперименты проводятся на датасете [Intel Image Classification](https://www.kaggle.com/puneet6060/intel-image-classification) из Kaggle с постепенным увеличением агрессивности аугментаций и изменением соотношения оригинальных и аугментированных данных.

### Анализ кода и результатов:

1. **Цель эксперимента**: Исследование влияния аугментаций на работу CNN.

2. **Архитектура модели**: 
   - Используется сверточная сеть BaseCNN с 4 сверточными слоями, Batch Normalization, MaxPooling, Dropout и тремя полносвязными слоями.
   - Модель обучается в течение 10 эпох с оптимизатором AdamW и планировщиком обучения ReduceLROnPlateau.

3. **Результаты обучения (без аугментаций)**:
   - Лучшая точность на валидации: 83.97%
   - Final training accuracy: 84.67%
   - Final validation accuracy: 82.90%
   - Наблюдается небольшой переобучение (разница между точностью на обучении и валидации).

4. **Визуализация**:
   - Построены графики обучения и валидации (loss и accuracy).
   - Графики показывают, что модель сходится, но есть признаки переобучения.

### Рекомендации для дальнейшего исследования:

1. **Добавление аугментаций**:
   - Для улучшения обобщающей способности модели и борьбы с переобучением следует добавить аугментации (например, случайные повороты, отражения, изменение яркости/контраста и т.д.).
   - Можно использовать библиотеку Albumentations для реализации аугментаций.

2. **Пример аугментаций**:
   ```python
   train_transform = A.Compose([
       A.Resize(150, 150),
       A.RandomRotate90(),
       A.HorizontalFlip(p=0.5),
       A.VerticalFlip(p=0.5),
       A.RandomBrightnessContrast(p=0.2),
       A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
       ToTensorV2()
   ])
   ```

3. **Сравнение результатов**:
   - После добавления аугментаций следует обучить модель заново и сравнить метрики (точность, потери) с базовой моделью.
   - Ожидается, что аугментации помогут уменьшить переобучение и улучшить результаты на валидационной выборке.

4. **Дополнительные эксперименты**:
   - Можно экспериментировать с различными аугментациями и их параметрами.
   - Также можно использовать более сложные архитектуры (например, предобученные модели) и сравнивать результаты.

### Вывод:
Без аугментаций модель показывает хорошую точность, но есть признаки переобучения. Добавление аугментаций может улучшить обобщающую способность модели и повысить точность на валидационной выборке. Рекомендуем провести дополнительные эксперименты с аугментациями и сравнить результаты.
