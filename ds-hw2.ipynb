{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":269359,"sourceType":"datasetVersion","datasetId":111880}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"c811892bc55d889f","cell_type":"markdown","source":"# Исследование влияния аугментаций на работу CNN","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}}},{"id":"b7ed88bcb4c27990","cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.functional import F\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\nfrom tqdm import tqdm\nfrom torchvision import transforms\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\n\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\nimport warnings\n\nwarnings.filterwarnings('ignore')\nplt.style.use('dark_background')\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"ExecuteTime":{"end_time":"2025-08-19T11:56:12.658203Z","start_time":"2025-08-19T11:56:06.080231Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T09:59:13.680323Z","iopub.execute_input":"2025-08-21T09:59:13.680844Z","iopub.status.idle":"2025-08-21T09:59:55.107450Z","shell.execute_reply.started":"2025-08-21T09:59:13.680810Z","shell.execute_reply":"2025-08-21T09:59:55.106828Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n  data = fetch_version_info()\n","output_type":"stream"}],"execution_count":1},{"id":"c354d083ae5da0d5","cell_type":"markdown","source":"## Скачиваем данные Intel Image Classification с Kaggle","metadata":{}},{"id":"d058dead30e2e9d","cell_type":"code","source":"# Классы датасета Intel Image classification\nclasses = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n\ntrain_path = '/kaggle/input/intel-image-classification/seg_train/seg_train'\nval_path = '/kaggle/input/intel-image-classification/seg_test/seg_test'\n\ntrain_img_path = []\ntrain_img_label = []\nfor folder in os.listdir(train_path):\n    for img in os.listdir(os.path.join(train_path, folder)):\n        train_img_path.append(os.path.join(train_path, folder, img))\n        train_img_label.append(classes.index(folder))\n\nval_img_path = []\nval_img_label = []\nfor folder in os.listdir(val_path):\n    for img in os.listdir(os.path.join(val_path, folder)):\n        val_img_path.append(os.path.join(val_path, folder, img))\n        val_img_label.append(classes.index(folder))","metadata":{"ExecuteTime":{"end_time":"2025-08-19T11:56:13.451470Z","start_time":"2025-08-19T11:56:13.447012Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T09:59:55.108648Z","iopub.execute_input":"2025-08-21T09:59:55.109404Z","iopub.status.idle":"2025-08-21T09:59:55.376182Z","shell.execute_reply.started":"2025-08-21T09:59:55.109382Z","shell.execute_reply":"2025-08-21T09:59:55.375635Z"}},"outputs":[],"execution_count":2},{"id":"cdb9b271d1228e6f","cell_type":"markdown","source":"# Подготовка датасета (до добавления аугментаций)","metadata":{}},{"id":"b8012406-a61f-41f5-94e8-55f8da002103","cell_type":"code","source":"# Для работы с библиотекой albumentations придется написать кастомный датасет\nclass MyDataset(Dataset):\n    def __init__(self, image_paths, labels, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image_path = self.image_paths[idx]\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        label = self.labels[idx]\n\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T09:59:55.376837Z","iopub.execute_input":"2025-08-21T09:59:55.377086Z","iopub.status.idle":"2025-08-21T09:59:55.382126Z","shell.execute_reply.started":"2025-08-21T09:59:55.377068Z","shell.execute_reply":"2025-08-21T09:59:55.381329Z"}},"outputs":[],"execution_count":3},{"id":"5e6a65d9a6f82737","cell_type":"code","source":"# Трансформации\ntrain_transform = A.Compose([\n    A.Resize(150, 150), # Выдавало ошибку, видимо некоторые изображения отличаются по размеру\n    A.Normalize(mean=(0.485, 0.456, 0.406), \n                std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])\n\nval_transform = A.Compose([\n    A.Resize(150, 150),\n    A.Normalize(mean=(0.485, 0.456, 0.406), \n                std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])\n\n# Dataloaders\ntrain_dataset = MyDataset(image_paths=train_img_path, labels=train_img_label, transform=train_transform)\ntrain_loader = DataLoader(train_dataset,\n                          batch_size=128,\n                          shuffle=True,\n                          num_workers=0, # Тоже проблему выдавало, оказывается из-за многопоточности\n                          pin_memory=True)\n\nval_dataset = MyDataset(image_paths=val_img_path, labels=val_img_label, transform=val_transform)\nval_loader = DataLoader(val_dataset,\n                        batch_size=128,\n                        shuffle=False,\n                        num_workers=0,\n                        pin_memory=True)\n\nprint(f'Обучающих примеров: {len(train_dataset)}')\nprint(f'Валидационных примеров: {len(val_dataset)}')\nprint(f'Количество классов: {len(classes)}')","metadata":{"ExecuteTime":{"end_time":"2025-08-19T12:19:47.598804Z","start_time":"2025-08-19T12:19:47.476487Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T09:59:55.383820Z","iopub.execute_input":"2025-08-21T09:59:55.384076Z","iopub.status.idle":"2025-08-21T09:59:55.405500Z","shell.execute_reply.started":"2025-08-21T09:59:55.384060Z","shell.execute_reply":"2025-08-21T09:59:55.404927Z"}},"outputs":[{"name":"stdout","text":"Обучающих примеров: 14034\nВалидационных примеров: 3000\nКоличество классов: 6\n","output_type":"stream"}],"execution_count":4},{"id":"e4e531c270825b5c","cell_type":"markdown","source":"# Создание базовой модели (Baseline)","metadata":{}},{"id":"35dd438559bfc33a","cell_type":"code","source":"class BaseCNN(nn.Module):\n    def __init__(self, num_classes=6):\n        super(BaseCNN, self).__init__()\n\n        # Convolutional layers\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n\n        # Batch Normalization layers\n        self.bn1 = nn.BatchNorm2d(32)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.bn4 = nn.BatchNorm2d(256)\n\n        # Pooling\n        self.pool = nn.MaxPool2d(2, 2)\n\n        # Dropout\n        self.dropout = nn.Dropout(0.5)\n\n        # Full connected layers\n        self.fc1 = nn.Linear(256 * 9 * 9, 512)\n        self.fc2 = nn.Linear(512, 128)\n        self.fc3 = nn.Linear(128, num_classes)\n\n    def forward(self, x):\n        # Convolution\n        x = self.pool(F.relu(self.bn1(self.conv1(x)))) # Conv1 -> BatchNorm1 -> ReLU -> MaxPooling\n        x = self.pool(F.relu(self.bn2(self.conv2(x)))) # Conv2 -> BatchNorm2 -> ReLU -> MaxPooling\n        x = self.pool(F.relu(self.bn3(self.conv3(x)))) # Conv3 -> BatchNorm3 -> ReLU -> MaxPooling\n        x = self.pool(F.relu(self.bn4(self.conv4(x)))) # Conv4 -> BatchNorm4 -> ReLU -> MaxPooling\n\n        # Flatten\n        x = x.view(x.size(0), -1)\n\n        # Full connection\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = self.fc3(x)\n\n        return x","metadata":{"ExecuteTime":{"end_time":"2025-08-19T12:19:47.633148Z","start_time":"2025-08-19T12:19:47.622395Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T09:59:55.406100Z","iopub.execute_input":"2025-08-21T09:59:55.406303Z","iopub.status.idle":"2025-08-21T09:59:55.420910Z","shell.execute_reply.started":"2025-08-21T09:59:55.406287Z","shell.execute_reply":"2025-08-21T09:59:55.420322Z"}},"outputs":[],"execution_count":5},{"id":"44e61cf96c86ad7d","cell_type":"code","source":"def train_epoch(model, train_loader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    pbar = tqdm(train_loader, desc='Training')\n    for batch_idx, (data, target) in enumerate(pbar):\n        data, target = data.to(device), target.to(device)\n\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        pred = output.argmax(dim=1, keepdim=True)\n        total += target.size(0)\n        correct += pred.eq(target.view_as(pred)).sum().item()\n\n        # Обновление прогресс-бара\n        pbar.set_postfix({\n            'Loss': f'{running_loss/total:.4f}',\n            'Acc': f'{100.*correct/total:.2f}%'\n        })\n\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n\n    return epoch_loss, epoch_acc\n\ndef val_epoch(model, val_loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    pbar = tqdm(val_loader, desc='Validation')\n    \n    with torch.no_grad():\n        for batch_idx, (data, target) in enumerate(pbar):\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            loss = criterion(output, target)\n    \n            running_loss += loss.item()\n            pred = output.argmax(dim=1, keepdim=True)\n            total += target.size(0)\n            correct += pred.eq(target.view_as(pred)).sum().item()\n    \n            # Обновление прогресс-бара\n            pbar.set_postfix({\n                'Loss': f'{running_loss/total:.4f}',\n                'Acc': f'{100.*correct/total:.2f}%'\n            })\n\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n\n    return epoch_loss, epoch_acc","metadata":{"ExecuteTime":{"end_time":"2025-08-19T12:19:47.658060Z","start_time":"2025-08-19T12:19:47.644002Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T09:59:55.421597Z","iopub.execute_input":"2025-08-21T09:59:55.421795Z","iopub.status.idle":"2025-08-21T09:59:55.440504Z","shell.execute_reply.started":"2025-08-21T09:59:55.421779Z","shell.execute_reply":"2025-08-21T09:59:55.439943Z"}},"outputs":[],"execution_count":6},{"id":"1231b9651f8ad6a2","cell_type":"code","source":"# Создадим модель сверточной нейросети\nmodel = BaseCNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-6)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')","metadata":{"ExecuteTime":{"end_time":"2025-08-19T12:19:47.741664Z","start_time":"2025-08-19T12:19:47.667319Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T09:59:55.441369Z","iopub.execute_input":"2025-08-21T09:59:55.441614Z","iopub.status.idle":"2025-08-21T09:59:55.730107Z","shell.execute_reply.started":"2025-08-21T09:59:55.441593Z","shell.execute_reply":"2025-08-21T09:59:55.729557Z"}},"outputs":[],"execution_count":7},{"id":"7911d11e162e8fc8","cell_type":"code","source":"# Основной цикл обучения\ndef train_model(model, criterion, optimizer, scheduler, epochs=20):\n    train_losses = []\n    train_accuracies = []\n    val_losses = []\n    val_accuracies = []\n\n    best_val_acc = 0.0\n    start_time = time.time()\n\n    print(\"Начинаем обучение...\")\n    print(\"=\" * 60)\n\n    for epoch in range(epochs):\n        epoch_start = time.time()\n\n        # Обучение\n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n\n        # Валидация\n        val_loss, val_acc = val_epoch(model, val_loader, criterion, device)\n\n        # Обновление планировщика\n        scheduler.step(val_loss)\n\n        # Сохранение метрик\n        train_losses.append(train_loss)\n        train_accuracies.append(train_acc)\n        val_losses.append(val_loss)\n        val_accuracies.append(val_acc)\n\n        # Время эпохи\n        epoch_time = time.time() - epoch_start\n\n        # Вывод результатов\n        print(f'\\nEpoch {epoch+1}/{epochs}:')\n        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100.:.2f}%')\n        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc*100.:.2f}%')\n        print(f'Time: {epoch_time:.1f}s, LR: {scheduler.get_last_lr()[0]:.6f}')\n\n        # Сохранение лучшей модели\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')\n            print(f'★ Новая лучшая модель! Accuracy: {best_val_acc*100.:.2f}%')\n\n        print(\"-\" * 60)\n\n    total_time = time.time() - start_time\n    print(f'\\nОбучение завершено!')\n    print(f'Общее время: {total_time/60:.1f} минут')\n    print(f'Лучшая валидационная точность: {best_val_acc*100.:.2f}%')\n\n    return train_losses, train_accuracies, val_losses, val_accuracies\n\n# Запуск обучения\nhistory = train_model(model, criterion, optimizer, scheduler)","metadata":{"ExecuteTime":{"end_time":"2025-08-19T12:22:19.200543Z","start_time":"2025-08-19T12:19:47.749925Z"},"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T09:59:55.730767Z","iopub.execute_input":"2025-08-21T09:59:55.730987Z"}},"outputs":[{"name":"stdout","text":"Начинаем обучение...\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 110/110 [01:55<00:00,  1.05s/it, Loss=0.0100, Acc=52.62%]\nValidation: 100%|██████████| 24/24 [00:23<00:00,  1.01it/s, Loss=0.0075, Acc=64.90%]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/20:\nTrain Loss: 0.0100, Train Acc: 52.62%\nVal Loss: 0.0075, Val Acc: 64.90%\nTime: 139.0s, LR: 0.001000\n★ Новая лучшая модель! Accuracy: 64.90%\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training:  79%|███████▉  | 87/110 [00:30<00:08,  2.62it/s, Loss=0.0063, Acc=70.56%]","output_type":"stream"}],"execution_count":null},{"id":"93ad1d5a-7575-4169-9c34-336e31a43b98","cell_type":"markdown","source":"# Анализ результатов","metadata":{}},{"id":"fd663d50248a4bb2","cell_type":"code","source":"def plot_training_history(history):\n    train_losses, train_accuracies, val_losses, val_accuracies = history\n    epochs = range(1, len(train_losses) + 1)\n    \n    fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n\n    # Loss plot\n    ax[0].plot(epochs, train_losses, 'bo-', label='Train loss', lw=2)\n    ax[0].plot(epochs, val_losses, 'ro-', label='Validation loss', lw=2)\n    ax[0].set_title('Training and Validation Loss')\n    ax[0].set_xlabel('Epochs')\n    ax[0].set_ylabel('Loss')\n    ax[0].legend()\n    ax[0].grid(True, alpha=0.3)\n\n    # Accuracy plot\n    ax[1].plot(epochs, train_accuracies, 'bo-', label='Train accuracy', lw=2)\n    ax[1].plot(epochs, val_accuracies, 'ro-', label='Validation accuracy', lw=2)\n    ax[1].set_title('Training and Validation Accuracy')\n    ax[1].set_xlabel('Epochs')\n    ax[1].set_ylabel('Accuracy')\n    ax[1].legend()\n    ax[1].grid(True, alpha=0.3)\n\n    plt.tight_layout()\n    plt.show()\n\n    best_train_acc = max(train_accuracies)\n    best_val_acc = max(val_accuracies)\n    final_train_loss = train_losses[-1]\n    final_val_loss = val_losses[-1]\n\n    print('Final results')\n    print(f'Best training accuracy: {best_train_acc*100.:.2f}%')\n    print(f'Best validation accuracy: {best_val_acc*100.:.2f}%')\n    print(f'Final train loss: {final_train_loss:.4f}')\n    print(f'Final validation loss: {final_val_loss:.4f}')\n\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9afc5bc9-2220-4e64-af69-61f9136cc96d","cell_type":"code","source":"# Детальная оценка на тестовом наборе\ndef evaluate_model(model, test_loader):\n    model.eval()\n    y_true = []\n    y_pred = []\n    y_proba = []\n    \n    with torch.no_grad():\n        for data, target in tqdm(test_loader, desc='Evaluation'):\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            pred = output.argmax(dim=1)\n            proba = F.softmax(output, dim=1)\n            \n            y_true.extend(target.cpu().numpy())\n            y_pred.extend(pred.cpu().numpy())\n            y_proba.extend(proba.cpu().numpy())\n    \n    return np.array(y_true), np.array(y_pred), np.array(y_proba)\n\ny_true, y_pred, y_proba = evaluate_model(model, val_loader)\n\n# Матрица ошибок\ndef plot_confusion_matrix(y_true, y_pred, classes):\n    cm = confusion_matrix(y_true, y_pred)\n    \n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=classes, yticklabels=classes)\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.tight_layout()\n    plt.show()\n    \n    # Accuracy по классам\n    class_accuracy = cm.diagonal() / cm.sum(axis=1)\n    \n    print(\"\\nТочность по классам:\")\n    for i, acc in enumerate(class_accuracy):\n        print(f\"{classes[i]}: {acc:.3f}\")\n\nplot_confusion_matrix(y_true, y_pred, classes)\n\n# Отчет по классификации\nprint(\"\\nДетальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"12482887-087a-4087-8de9-695a2971d874","cell_type":"code","source":"# Визуализация предсказаний\ndef visualize_predictions(model, test_loader, classes, num_images=20):\n    model.eval()\n    images_shown = 0\n    \n    fig, axes = plt.subplots(5, 4, figsize=(15, 15))\n    axes = axes.ravel()\n    \n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            pred = output.argmax(dim=1)\n            proba = F.softmax(output, dim=1)\n            \n            for i in range(data.size(0)):\n                if images_shown >= num_images:\n                    break\n                \n                img = data[i].cpu()\n                img = torch.clamp(img, 0, 1)\n                \n                # Отображение\n                axes[images_shown].imshow(img.permute(1, 2, 0))\n                \n                true_label = classes[target[i]]\n                pred_label = classes[pred[i]]\n                confidence = proba[i][pred[i]].item()\n                \n                # Цвет: зеленый для правильных, красный для неправильных\n                color = 'green' if target[i] == pred[i] else 'red'\n                \n                axes[images_shown].set_title(\n                    f'True: {true_label}\\nPred: {pred_label} ({confidence:.2f})',\n                    color=color, fontsize=10\n                )\n                axes[images_shown].axis('off')\n                \n                images_shown += 1\n            \n            if images_shown >= num_images:\n                break\n    \n    plt.tight_layout()\n    plt.show()\n\nvisualize_predictions(model, val_loader, classes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"19a27f03-f533-4ef8-82b8-b61e57773872","cell_type":"markdown","source":"# Добавление аугментаций","metadata":{}},{"id":"b9c0ef81-e622-4523-a232-7ac2865e48f1","cell_type":"markdown","source":"## 1. Базовые геометрические преобразования\n* Горизонтальные отражения (horizontal flip)\n* Повороты (rotation) ±15°\n","metadata":{}},{"id":"2e1b70fb-4d7e-4480-b41c-a0456a1af932","cell_type":"code","source":"def run_experiment(ratio):\n    # Создадим модель сверточной нейросети\n    model = BaseCNN().to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-6)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n\n    # Training\n    train_transform = A.Compose([\n        A.Resize(150, 150),\n        A.HorizontalFlip(p=ratio),\n        A.Rotate(limit=(-15, 15), p=ratio),\n        A.Normalize(mean=(0.485, 0.456, 0.406), \n                    std=(0.229, 0.224, 0.225)),\n        ToTensorV2()\n    ])\n    train_dataset = MyDataset(image_paths=train_img_path, \n                              labels=train_img_label, \n                              transform=train_transform)\n    train_loader = DataLoader(train_dataset,\n                              batch_size=128,\n                              shuffle=True,\n                              num_workers=0,\n                              pin_memory=True)\n\n    # Validation\n    val_transform = A.Compose([\n        A.Resize(150, 150),\n        A.Normalize(mean=(0.485, 0.456, 0.406), \n                    std=(0.229, 0.224, 0.225)),\n        ToTensorV2()\n    ])\n    val_dataset = MyDataset(image_paths=val_img_path, \n                            labels=val_img_label, \n                            transform=val_transform)\n    val_loader = DataLoader(val_dataset,\n                            batch_size=128,\n                            shuffle=False,\n                            num_workers=0,\n                            pin_memory=True)\n    \n    # Запуск обучения\n    history = train_model(model, criterion, optimizer, scheduler)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4bfa7ae3-7cc8-4cdf-9603-693e9a3d6f95","cell_type":"markdown","source":"### 25% аугментированных данных","metadata":{}},{"id":"6196d3a6-96d4-4da0-ab49-35ce245970b2","cell_type":"code","source":"run_experiment(ratio=0.25)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"495cdd7e-47af-4f85-a6cd-b7584ddaa5ea","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"506c3701-e9b9-4cb1-a0d3-c94046914247","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"faf67def-5909-4f1a-9805-47b0386ce609","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6724ec06-6224-42a8-8eaa-1ed45ccb3709","cell_type":"markdown","source":"### 50% аугментированных данных","metadata":{}},{"id":"e6a5cc61-58f6-4ea4-ac5b-9b873624f060","cell_type":"code","source":"run_experiment(ratio=0.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"56ae859b-9bac-4177-a222-923fde5ec03c","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5f9b8be2-430b-4e92-947a-1c95ee7ca107","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3b6ee2b5-b927-4104-8b0f-3c33ca450659","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1e081e0d-7069-4d82-8d12-d1db49280a29","cell_type":"markdown","source":"### 75% аугментированных данных","metadata":{}},{"id":"ffbcdb00-50dd-43e4-813b-4d23e06274a5","cell_type":"code","source":"run_experiment(ratio=0.75)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b18b4e12-69e1-4bdd-a416-9cdd93005aba","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"de7b4c85-315d-4eda-bd22-1b1afb805f89","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"bd25feb1-4196-4e8f-889c-cd64b98fa7bc","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"597ef58a-16f1-4141-8975-78ea89c1cfc0","cell_type":"markdown","source":"### 100% аугментированных данных","metadata":{}},{"id":"d5c2676b-a10c-4d98-8df7-2471cf2c7786","cell_type":"code","source":"run_experiment(ratio=1.0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"90e1adcd-cb08-4c8f-a5a5-a964b54e820a","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0683b7e0-26f6-49ed-9653-bfa2d6ecc1ad","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"782d1c61-3239-4df0-a22a-e68c6c88aaee","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"fd700e40-48b7-4f0c-b25a-bf9571831899","cell_type":"markdown","source":"## 2. Добавление искажений\n* Предыдущие аугментации +\n* Случайный зум (random zoom) ±10%\n* Сдвиги (translation) ±10%","metadata":{}},{"id":"f2b5b4b2-2b29-4ccb-8490-c9d3e159c219","cell_type":"code","source":"def run_experiment(ratio):\n    # Создадим модель сверточной нейросети\n    model = BaseCNN().to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-6)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n\n    # Training\n    train_transform = A.Compose([\n        A.Resize(150, 150),\n        A.HorizontalFlip(p=ratio),\n        A.Rotate(limit=(-15, 15), p=ratio),\n        A.RandomScale(scale_limit=(0.9, 1.1), p=ratio),\n        A.ShiftScaleRotate(shift_limit=(0.1, 0.1), scale_limit=0, \n                           rotate_limit=0, border_mode=cv2.BORDER_REFLECT, p=ratio),\n        A.Normalize(mean=(0.485, 0.456, 0.406), \n                    std=(0.229, 0.224, 0.225)),\n        ToTensorV2()\n    ])\n    train_dataset = MyDataset(image_paths=train_img_path, \n                              labels=train_img_label, \n                              transform=train_transform)\n    train_loader = DataLoader(train_dataset,\n                              batch_size=128,\n                              shuffle=True,\n                              num_workers=0,\n                              pin_memory=True)\n\n    # Validation\n    val_transform = A.Compose([\n        A.Resize(150, 150),\n        A.Normalize(mean=(0.485, 0.456, 0.406), \n                    std=(0.229, 0.224, 0.225)),\n        ToTensorV2()\n    ])\n    val_dataset = MyDataset(image_paths=val_img_path, \n                            labels=val_img_label, \n                            transform=val_transform)\n    val_loader = DataLoader(val_dataset,\n                            batch_size=128,\n                            shuffle=False,\n                            num_workers=0,\n                            pin_memory=True)\n    \n    # Запуск обучения\n    history = train_model(model, criterion, optimizer, scheduler)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ec94627b-21e6-4ab9-a39d-e1af46703746","cell_type":"markdown","source":"### 25% аугментированных данных","metadata":{}},{"id":"38f19180-3105-4441-8dc7-ce82ad9f8b69","cell_type":"code","source":"run_experiment(ratio=0.25)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6cee559d-9795-45c3-a6d8-ba2e169114ca","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c10d24e0-f414-4165-b1ca-8cd78c18fd33","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"887ec516-b6df-4bee-9b7a-08576b5a78d5","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a000c411-9e95-457e-8735-282c204659cd","cell_type":"markdown","source":"### 50% аугментированных данных","metadata":{}},{"id":"7c5efa1b-75ef-440b-b34d-feec6985d390","cell_type":"code","source":"run_experiment(ratio=0.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"28bb9a2b-c954-4914-a279-6178c51d7c10","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ffd6e96f-ac6f-4e87-b6e1-e7ed18d18940","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"155afb33-959d-4dbf-ad47-688dbb087fdd","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"990685b3-ac91-4bcc-8b73-5b284727da0c","cell_type":"markdown","source":"### 75% аугментированных данных","metadata":{}},{"id":"1d9bcc3f-04a7-488e-9207-5a1c11902ce6","cell_type":"code","source":"run_experiment(ratio=0.75)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"580d799f-6427-4581-9bbd-07c11940adc7","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"14dec07a-a9b4-4fd0-b46f-1b718594ccae","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2b6b08bc-2ea3-42aa-9f57-ce8836c33cdd","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d8d5bbda-da4c-4855-abbf-ed74967d7745","cell_type":"markdown","source":"### 100% аугментированных данных","metadata":{}},{"id":"82c7b4ae-6cae-4040-9a64-5185d3681563","cell_type":"code","source":"run_experiment(ratio=1.0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4e87b1da-dca5-4ffa-bee7-dc2ab85a7cb6","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3d1ef0c2-0e53-42d9-aa9f-88e36dae2701","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f9e72ab2-816d-47c3-9fae-056b3ebeddbc","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"16a095ac-7ca8-4503-9469-e8fd15c26355","cell_type":"markdown","source":"## 3. Цветовые и яркостные преобразования\n* Предыдущие аугментации +\n* Изменение яркости (brightness) ±20%\n* Изменение контраста (contrast) ±20%","metadata":{}},{"id":"e45e4dbb-56da-4f2f-9b26-e66adcded807","cell_type":"code","source":"def run_experiment(ratio):\n    # Создадим модель сверточной нейросети\n    model = BaseCNN().to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-6)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n\n    # Training\n    train_transform = A.Compose([\n        A.Resize(150, 150),\n        A.HorizontalFlip(p=ratio),\n        A.Rotate(limit=(-15, 15), p=ratio),\n        A.RandomScale(scale_limit=(0.9, 1.1), p=ratio),\n        A.ShiftScaleRotate(shift_limit=(0.1, 0.1), scale_limit=0, \n                           rotate_limit=0, border_mode=cv2.BORDER_REFLECT, p=ratio),\n        A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=ratio),\n        A.Normalize(mean=(0.485, 0.456, 0.406), \n                    std=(0.229, 0.224, 0.225)),\n        ToTensorV2()\n    ])\n    train_dataset = MyDataset(image_paths=train_img_path, \n                              labels=train_img_label, \n                              transform=train_transform)\n    train_loader = DataLoader(train_dataset,\n                              batch_size=128,\n                              shuffle=True,\n                              num_workers=0,\n                              pin_memory=True)\n\n    # Validation\n    val_transform = A.Compose([\n        A.Resize(150, 150),\n        A.Normalize(mean=(0.485, 0.456, 0.406), \n                    std=(0.229, 0.224, 0.225)),\n        ToTensorV2()\n    ])\n    val_dataset = MyDataset(image_paths=val_img_path, \n                            labels=val_img_label, \n                            transform=val_transform)\n    val_loader = DataLoader(val_dataset,\n                            batch_size=128,\n                            shuffle=False,\n                            num_workers=0,\n                            pin_memory=True)\n    \n    # Запуск обучения\n    history = train_model(model, criterion, optimizer, scheduler)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a22973ed-d453-40d3-9b4c-f4948e8704f9","cell_type":"markdown","source":"### 25% аугментированных данных","metadata":{}},{"id":"449afa44-204b-4a0b-9207-04541efce9d1","cell_type":"code","source":"run_experiment(ratio=0.25)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c21fc0f2-3182-491a-b5ce-881ae7304f84","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8b05aa65-6815-4cd6-8b97-d9e5627775d2","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3148337f-5008-42ac-bfff-fd5f509eb3e0","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4044dc9b-3b97-4988-b107-f5f35141c2c8","cell_type":"markdown","source":"### 50% аугментированных данных","metadata":{}},{"id":"5852b48b-785f-42f3-8d9a-e55590060e6d","cell_type":"code","source":"run_experiment(ratio=0.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2795ad3d-97ae-4dad-b294-b5f5928b44ae","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5e6e1525-82a0-4da3-8d6f-24197301a880","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f9647753-6528-4f84-90e0-0644688d6ec8","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"95327023-ad98-4074-9017-babb3669e76a","cell_type":"markdown","source":"### 75% аугментированных данных","metadata":{}},{"id":"e4f3dc3a-0600-42aa-bdfa-5213858e05e6","cell_type":"code","source":"run_experiment(ratio=0.75)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"38f6648c-a250-4d78-8914-9d264c30c4c6","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d2b2671b-63fa-4edb-8195-248904c2d502","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d439979d-561a-426a-a510-06c7ac5484e5","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b83a27e5-a1c2-4638-b84d-23cf06f6ffb7","cell_type":"markdown","source":"### 100% аугментированных данных","metadata":{}},{"id":"63946942-d92d-460f-814c-07855c2214ec","cell_type":"code","source":"run_experiment(ratio=1.0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a1878283-290b-4b1a-a8cf-472515a026df","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a9d27681-ce99-46f2-8861-24f377489c4a","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b9a4d347-f178-43b5-8088-ed5ddf02631c","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7193e93a-0257-4fbc-99b9-ad1bd1e16dca","cell_type":"markdown","source":"## 4. Продвинутые техники\n* Предыдущие аугментации +\n* Размытие (Gaussian blur)\n* Добавление шума (noise injection)","metadata":{}},{"id":"f9fff2f5-3172-4c29-bc56-afa01eda3558","cell_type":"code","source":"def run_experiment(ratio):\n    # Создадим модель сверточной нейросети\n    model = BaseCNN().to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-6)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n\n    # Training\n    train_transform = A.Compose([\n        A.Resize(150, 150),\n        A.HorizontalFlip(p=ratio),\n        A.Rotate(limit=(-15, 15), p=ratio),\n        A.RandomScale(scale_limit=(0.9, 1.1), p=ratio),\n        A.ShiftScaleRotate(shift_limit=(0.1, 0.1), scale_limit=0, \n                           rotate_limit=0, border_mode=cv2.BORDER_REFLECT, p=ratio),\n        A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=ratio),\n        A.GaussianBlur(sigma_limit=(0.1, 0.2), p=ratio),\n        A.GaussNoise(p=ratio),\n        A.Normalize(mean=(0.485, 0.456, 0.406), \n                    std=(0.229, 0.224, 0.225)),\n        ToTensorV2()\n    ])\n    train_dataset = MyDataset(image_paths=train_img_path, \n                              labels=train_img_label, \n                              transform=train_transform)\n    train_loader = DataLoader(train_dataset,\n                              batch_size=128,\n                              shuffle=True,\n                              num_workers=0,\n                              pin_memory=True)\n\n    # Validation\n    val_transform = A.Compose([\n        A.Resize(150, 150),\n        A.Normalize(mean=(0.485, 0.456, 0.406), \n                    std=(0.229, 0.224, 0.225)),\n        ToTensorV2()\n    ])\n    val_dataset = MyDataset(image_paths=val_img_path, \n                            labels=val_img_label, \n                            transform=val_transform)\n    val_loader = DataLoader(val_dataset,\n                            batch_size=128,\n                            shuffle=False,\n                            num_workers=0,\n                            pin_memory=True)\n    \n    # Запуск обучения\n    history = train_model(model, criterion, optimizer, scheduler)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"26587a82-882f-49af-a664-782becc4f63f","cell_type":"markdown","source":"### 25% аугментированных данных","metadata":{}},{"id":"c2005a3d-137a-4323-ad0b-52eef23b9df3","cell_type":"code","source":"run_experiment(ratio=0.25)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"015d270c-3bb0-411b-bb3e-05938e9e7692","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"574964a1-6ca5-433f-920f-85179a223967","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b8c02460-4789-47c5-90d7-9d4948fe4149","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9d384f9b-70ee-4a38-95eb-cf7ce0bab018","cell_type":"markdown","source":"### 50% аугментированных данных","metadata":{}},{"id":"8f991de2-2495-4541-861c-0ccdc8c51db2","cell_type":"code","source":"run_experiment(ratio=0.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"57cfa89c-28ed-482c-bd4c-66dc51db4a83","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ad3dc585-a2bd-4d0c-9b2a-e3d7ee590e40","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"70ee1da0-23b3-43aa-8387-a4c2cab98ff1","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"30020d86-d4d6-4868-a3ee-5aaf75f29f3e","cell_type":"markdown","source":"### 75% аугментированных данных","metadata":{}},{"id":"acc31a72-8b7c-4eb6-89bd-665e48d0a1a5","cell_type":"code","source":"run_experiment(ratio=0.75)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7ed360ca-79ad-4257-b824-43572a5b718e","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0adf5c4c-ca6e-4884-bce8-1f8c582dcd3b","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"637678f0-0486-4225-a485-a7209d832b7a","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1836f2c2-94e2-4d16-ab52-5ff6ae72441e","cell_type":"markdown","source":"### 100% аугментированных данных","metadata":{}},{"id":"4a6e54e0-cbf2-4956-83fb-6e1af5062fab","cell_type":"code","source":"run_experiment(ratio=1.0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a608d7ea-a957-42f2-abb7-ca93f1b02fb5","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b05645e0-18dc-4da8-ba9d-33a465c30d32","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"be842753-b874-457c-81c7-56e368bef05b","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0adbe788-7e76-4c09-8fdb-7123f99f6e94","cell_type":"markdown","source":"## 5. Современные аугментации\n* Предыдущие аугментации +\n* Random Erasing\n* CutMix","metadata":{}},{"id":"be693eb1-1701-4932-bdb6-9dca40bab0cc","cell_type":"code","source":"# CutMix в Albumentations нет, придется писать кастомный\nclass CutMix(A.DualTransform):\n    def __init__(self, always_apply=False, p=0.5):\n        super().__init__(always_apply, p)\n\n    def apply(self, image, **params):\n        return image\n\n    def get_params_dependent_on_targets(self, params):\n        image = params[\"image\"]\n        h, w, _ = image.shape\n        cut_w = w // 2\n        cut_h = h // 2\n        x1 = np.random.randint(0, w - cut_w)\n        y1 = np.random.randint(0, h - cut_h)\n        return {\"x1\": x1, \"y1\": y1, \"cut_w\": cut_w, \"cut_h\": cut_h}\n\n    def apply_with_other(self, image, other_image, x1, y1, cut_w, cut_h, **params):\n        img = image.copy()\n        img[y1:y1+cut_h, x1:x1+cut_w] = other_image[y1:y1+cut_h, x1:x1+cut_w]\n        return img\n\n    @property\n    def targets_as_params(self):\n        return [\"image\"]\n\n    def update_params(self, params, **kwargs):\n        return params","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"95b72960-76b3-4784-8afc-778d5e230c35","cell_type":"code","source":"def run_experiment(ratio):\n    # Создадим модель сверточной нейросети\n    model = BaseCNN().to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-6)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n\n    # Training\n    train_transform = A.Compose([\n        A.Resize(150, 150),\n        A.HorizontalFlip(p=ratio),\n        A.Rotate(limit=(-15, 15), p=ratio),\n        A.RandomScale(scale_limit=(0.9, 1.1), p=ratio),\n        A.ShiftScaleRotate(shift_limit=(0.1, 0.1), scale_limit=0, \n                           rotate_limit=0, border_mode=cv2.BORDER_REFLECT, p=ratio),\n        A.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), p=ratio),\n        A.GaussianBlur(sigma_limit=(0.1, 0.2), p=ratio),\n        A.GaussNoise(p=ratio),\n        A.Erasing(p=ratio),\n        CutMix(p=ratio),\n        A.Normalize(mean=(0.485, 0.456, 0.406), \n                    std=(0.229, 0.224, 0.225)),\n        ToTensorV2()\n    ])\n    train_dataset = MyDataset(image_paths=train_img_path, \n                              labels=train_img_label, \n                              transform=train_transform)\n    train_loader = DataLoader(train_dataset,\n                              batch_size=128,\n                              shuffle=True,\n                              num_workers=0,\n                              pin_memory=True)\n\n    # Validation\n    val_transform = A.Compose([\n        A.Resize(150, 150),\n        A.Normalize(mean=(0.485, 0.456, 0.406), \n                    std=(0.229, 0.224, 0.225)),\n        ToTensorV2()\n    ])\n    val_dataset = MyDataset(image_paths=val_img_path, \n                            labels=val_img_label, \n                            transform=val_transform)\n    val_loader = DataLoader(val_dataset,\n                            batch_size=128,\n                            shuffle=False,\n                            num_workers=0,\n                            pin_memory=True)\n    \n    # Запуск обучения\n    history = train_model(model, criterion, optimizer, scheduler)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"545ed956-3499-4dc7-ba8d-0cf6f4fd8494","cell_type":"markdown","source":"### 25% аугментированных данных","metadata":{}},{"id":"f0335c84-a0fd-4c6d-b398-e8958d0d3151","cell_type":"code","source":"run_experiment(ratio=0.25)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"494ec30a-6212-46dc-b3a5-288c2825cba1","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"dc61c809-5d9c-4dc7-afd4-c44f6b92b88e","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c5113c62-a566-4201-b3ef-b6ee337f6a93","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c1a4306f-ca16-4c78-b237-063bec5bd179","cell_type":"markdown","source":"### 50% аугментированных данных","metadata":{}},{"id":"e61004e0-9098-4131-ae39-c91ebced9eac","cell_type":"code","source":"run_experiment(ratio=0.5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b45e1bab-a498-4e68-80ae-7a1cb9944b74","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3fa7cc28-c921-475d-a67e-9cd96b523dce","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ea0b3c03-c95b-469a-8436-0260f13c2728","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3ae0ad4d-5d18-459f-85f3-61ea229d18dc","cell_type":"markdown","source":"### 75% аугментированных данных","metadata":{}},{"id":"3f36835b-61b2-4e83-88a0-74d8d6bc4d8d","cell_type":"code","source":"run_experiment(ratio=0.75)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e376007b-6ee1-4539-9a82-a0654f9e3768","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"54f2a5b2-62ad-4c1b-af50-f11f855af1c7","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"29b43f7e-d4e5-4043-bb78-6eccddbafbc7","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"01b0901c-7b03-4a71-bfe3-05973e2a4a6a","cell_type":"markdown","source":"### 100% аугментированных данных","metadata":{}},{"id":"21f325f5-153f-4ce8-a594-49d4b0e79826","cell_type":"code","source":"run_experiment(ratio=1.0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d0cb4c14-213c-4482-8a71-a0056570373c","cell_type":"code","source":"# Графики потерь и точности\nplot_training_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1860ccc0-a4e1-4e0c-a99d-5800996eaab0","cell_type":"code","source":"y_true, y_pred, y_proba = evaluate_model(model, val_loader) # Оценка на тестовом наборе\nplot_confusion_matrix(y_true, y_pred, classes) # Матрица ошибок","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1f0e6e1a-2553-48c9-8733-9a906637b1cf","cell_type":"code","source":"# Отчет по классификации\nprint(\"Детальный отчет:\")\nprint(classification_report(y_true, y_pred, target_names=classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"7680fd59-7bcc-4538-9681-2d313517ad7e","cell_type":"markdown","source":"# Исследовательские вопросы для анализа","metadata":{}},{"id":"38e8a59b-6841-46a4-9cf0-db13ef2e91e8","cell_type":"markdown","source":"## 1. Какое соотношение аугментированных данных к исходным является оптимальным?","metadata":{}},{"id":"656f1241-a8f5-4120-9623-8c9afa2e074c","cell_type":"markdown","source":"### Ответ","metadata":{}},{"id":"17f66e08-6652-4f31-9830-858b77f6c8e0","cell_type":"markdown","source":"## 2. Зависит ли качество предсказаний от количества различных способов аугментации?","metadata":{}},{"id":"6aa308f8-959b-467e-ada1-d7e41dd1518e","cell_type":"markdown","source":"### Ответ","metadata":{}},{"id":"1b0dec96-c660-47fb-8c92-d939cbafd092","cell_type":"markdown","source":"## 3. На каком этапе добавления аугментаций наблюдается наибольший прирост качества?","metadata":{}},{"id":"54e1fe33-ed95-4800-a4b9-2eb8e1179d64","cell_type":"markdown","source":"### Ответ","metadata":{}},{"id":"868f10f2-6980-47fe-809c-7e3381fbecba","cell_type":"markdown","source":"## 4. Есть ли признак переобучения при использовании слишком агрессивных аугментаций?","metadata":{}},{"id":"d919e9da-8303-4e9d-8d8e-c173d45c8c2b","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}